# BLASSO_SA
MAP estimation of the Bayesian LASSO via Simulated Annealing.

# Sampler
The Simulated Annealing is based on the Gibbs sampler presented in [1] (with marginalized out &#956;).
<a href="https://www.codecogs.com/eqnedit.php?latex=\begin{array}{llcl}&space;&&&A&space;=&space;X^TX&space;&plus;&space;D_\tau^{-1}&space;\\&space;&&&D_\tau&space;=&space;diag(\tau_1^2,\dots,\tau_p^2)&space;\\&space;\\&space;\beta&space;&|&space;\quad&space;\tilde{y},&space;\sigma^2,&space;\tau_1^2,&space;\dots,&space;\tau_p^2&space;&\sim&&space;\mathcal{N}(A^{-1}&space;X^T\tilde{y},&space;\sigma^2&space;A^{-1})&space;\\&space;\sigma^2&space;&|\quad\tilde{y},&space;\beta,\tau_1^2,\dots,\tau_p^2&space;&\sim&&space;InvGamma\Big(\frac{1}{2}(n-1&plus;p),&space;\frac{1}{2}&space;\big((\tilde{y}-X\beta)^T&space;(\tilde{y}-X\beta)&plus;&space;\beta^TD_\tau^{-1}\beta\big)\Big)&space;\\&space;1/\tau_j^2&space;&|\quad&space;\tilde{y},&space;\beta,&space;\tau_{-j}^2&space;&\sim&&space;InvGauss\Big(\mu'=\sqrt{\frac{\lambda^2\sigma^2}{\beta_j^2}},&space;\lambda'=\lambda^2&space;\Big)&space;\end{array}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{array}{llcl}&space;&&&A&space;=&space;X^TX&space;&plus;&space;D_\tau^{-1}&space;\\&space;&&&D_\tau&space;=&space;diag(\tau_1^2,\dots,\tau_p^2)&space;\\&space;\\&space;\beta&space;&|&space;\quad&space;\tilde{y},&space;\sigma^2,&space;\tau_1^2,&space;\dots,&space;\tau_p^2&space;&\sim&&space;\mathcal{N}(A^{-1}&space;X^T\tilde{y},&space;\sigma^2&space;A^{-1})&space;\\&space;\sigma^2&space;&|\quad\tilde{y},&space;\beta,\tau_1^2,\dots,\tau_p^2&space;&\sim&&space;InvGamma\Big(\frac{1}{2}(n-1&plus;p),&space;\frac{1}{2}&space;\big((\tilde{y}-X\beta)^T&space;(\tilde{y}-X\beta)&plus;&space;\beta^TD_\tau^{-1}\beta\big)\Big)&space;\\&space;1/\tau_j^2&space;&|\quad&space;\tilde{y},&space;\beta,&space;\tau_{-j}^2&space;&\sim&&space;InvGauss\Big(\mu'=\sqrt{\frac{\lambda^2\sigma^2}{\beta_j^2}},&space;\lambda'=\lambda^2&space;\Big)&space;\end{array}" title="\begin{array}{llcl} &&&A = X^TX + D_\tau^{-1} \\ &&&D_\tau = diag(\tau_1^2,\dots,\tau_p^2) \\ \\ \beta &| \quad \tilde{y}, \sigma^2, \tau_1^2, \dots, \tau_p^2 &\sim& \mathcal{N}(A^{-1} X^T\tilde{y}, \sigma^2 A^{-1}) \\ \sigma^2 &|\quad\tilde{y}, \beta,\tau_1^2,\dots,\tau_p^2 &\sim& InvGamma\Big(\frac{1}{2}(n-1+p), \frac{1}{2} \big((\tilde{y}-X\beta)^T (\tilde{y}-X\beta)+ \beta^TD_\tau^{-1}\beta\big)\Big) \\ 1/\tau_j^2 &|\quad \tilde{y}, \beta, \tau_{-j}^2 &\sim& InvGauss\Big(\mu'=\sqrt{\frac{\lambda^2\sigma^2}{\beta_j^2}}, \lambda'=\lambda^2 \Big) \end{array}" /></a>

Cooling down of the posterior conditionals can be achieved by a parameter shift of the distributions. For the Inverse Gaussian distribution we make use of the fact that we can represent an IG as a <a href="https://en.wikipedia.org/wiki/Generalized_inverse_Gaussian_distribution">Generalized Inverse Gaussian</a>
with p=-0.5.

Let <i>T</i> be the current (positive) Temperature. Then we can sample according to:
<a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\begin{array}{llcl}&space;&&&T&space;\in&space;\mathbb{R}_{>0}&space;\\&space;\\&space;&&&A&space;=&space;X^TX&space;&plus;&space;D_\tau^{-1}&space;\\&space;&&&D_\tau&space;=&space;diag(\tau_1^2,\dots,\tau_p^2)&space;\\&space;\\&space;\beta&space;&|&space;\quad&space;\tilde{y},&space;\sigma^2,&space;\tau_1^2,&space;\dots,&space;\tau_p^2,&space;T&space;&\sim&&space;\mathcal{N}(A^{-1}&space;X^T\tilde{y},&space;\sigma^2&space;T&space;A^{-1})&space;\\&space;\sigma^2&space;&|\quad\tilde{y},&space;\beta,\tau_1^2,\dots,\tau_p^2,&space;T&space;&\sim&&space;InvGamma\Big(\frac{\frac{1}{2}(n-1&plus;p)&plus;1}{T}&space;-1,&space;\frac{\frac{1}{2}&space;\big((\tilde{y}-X\beta)^T&space;(\tilde{y}-X\beta)&plus;&space;\beta^TD_\tau^{-1}\beta\big)}{T}\Big)&space;\\&space;1/\tau_j^2&space;&|\quad&space;\tilde{y},&space;\beta,&space;\tau_{-j}^2,&space;T&space;&\sim&&space;GIG\Big(a'=\frac{\lambda'/\mu'^2}{T},&space;b'=\frac{\lambda'}{T},&space;p'=(-\frac{1.5}{T}&plus;1)\Big)&space;\\&space;&&&\mu'=\sqrt{\frac{\lambda^2\sigma^2}{\beta_j^2}}&space;\\&space;&&&\lambda'=\lambda^2&space;\end{array}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\large&space;\begin{array}{llcl}&space;&&&T&space;\in&space;\mathbb{R}_{>0}&space;\\&space;\\&space;&&&A&space;=&space;X^TX&space;&plus;&space;D_\tau^{-1}&space;\\&space;&&&D_\tau&space;=&space;diag(\tau_1^2,\dots,\tau_p^2)&space;\\&space;\\&space;\beta&space;&|&space;\quad&space;\tilde{y},&space;\sigma^2,&space;\tau_1^2,&space;\dots,&space;\tau_p^2,&space;T&space;&\sim&&space;\mathcal{N}(A^{-1}&space;X^T\tilde{y},&space;\sigma^2&space;T&space;A^{-1})&space;\\&space;\sigma^2&space;&|\quad\tilde{y},&space;\beta,\tau_1^2,\dots,\tau_p^2,&space;T&space;&\sim&&space;InvGamma\Big(\frac{\frac{1}{2}(n-1&plus;p)&plus;1}{T}&space;-1,&space;\frac{\frac{1}{2}&space;\big((\tilde{y}-X\beta)^T&space;(\tilde{y}-X\beta)&plus;&space;\beta^TD_\tau^{-1}\beta\big)}{T}\Big)&space;\\&space;1/\tau_j^2&space;&|\quad&space;\tilde{y},&space;\beta,&space;\tau_{-j}^2,&space;T&space;&\sim&&space;GIG\Big(a'=\frac{\lambda'/\mu'^2}{T},&space;b'=\frac{\lambda'}{T},&space;p'=(-\frac{1.5}{T}&plus;1)\Big)&space;\\&space;&&&\mu'=\sqrt{\frac{\lambda^2\sigma^2}{\beta_j^2}}&space;\\&space;&&&\lambda'=\lambda^2&space;\end{array}" title="\large \begin{array}{llcl} &&&T \in \mathbb{R}_{>0} \\ \\ &&&A = X^TX + D_\tau^{-1} \\ &&&D_\tau = diag(\tau_1^2,\dots,\tau_p^2) \\ \\ \beta &| \quad \tilde{y}, \sigma^2, \tau_1^2, \dots, \tau_p^2, T &\sim& \mathcal{N}(A^{-1} X^T\tilde{y}, \sigma^2 T A^{-1}) \\ \sigma^2 &|\quad\tilde{y}, \beta,\tau_1^2,\dots,\tau_p^2, T &\sim& InvGamma\Big(\frac{\frac{1}{2}(n-1+p)+1}{T} -1, \frac{\frac{1}{2} \big((\tilde{y}-X\beta)^T (\tilde{y}-X\beta)+ \beta^TD_\tau^{-1}\beta\big)}{T}\Big) \\ 1/\tau_j^2 &|\quad \tilde{y}, \beta, \tau_{-j}^2, T &\sim& GIG\Big(a'=\frac{\lambda'/\mu'^2}{T}, b'=\frac{\lambda'}{T}, p'=(-\frac{1.5}{T}+1)\Big) \\ &&&\mu'=\sqrt{\frac{\lambda^2\sigma^2}{\beta_j^2}} \\ &&&\lambda'=\lambda^2 \end{array}" /></a>


# Status
In Progress

# References

[1] <a href="https://www.tandfonline.com/doi/abs/10.1198/016214508000000337">Park, Trevor, and George Casella. "The bayesian lasso." Journal of the American Statistical Association 103.482 (2008): 681-686.</a>
